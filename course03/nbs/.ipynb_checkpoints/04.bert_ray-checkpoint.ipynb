{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text articles: 777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from transformers import pipeline\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import psutil\n",
    "import ray\n",
    "import os\n",
    "# os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = \"python\" \n",
    "# Load 20newsgroups news articles that that belong to “rec.motorcycles” and “rec.sport.baseball” classes of the test set only\n",
    "test_data = fetch_20newsgroups(subset='test', shuffle=False, categories=['rec.motorcycles', 'rec.sport.baseball'], remove=('headers', 'footers', 'quotes'))\n",
    "# Remove empty news article texts\n",
    "test_data = [text for text in test_data.data if text!='']\n",
    "print('Number of text articles:', len(test_data))\n",
    "\n",
    "\"\"\"\n",
    "HuggingFace pipelines are objects that abstract most of the complex code from the library, \n",
    "offering a simple API dedicated to several tasks, including text classification.\n",
    "All pipelines can use batching.\n",
    "However, this is not automatically a win for performance. \n",
    "It can be either a 10x speedup or 5x slowdown depending on hardware, data and the actual model being used.\n",
    "Batching is only recommended on GPU. \n",
    "If you are using CPU, don’t batch.\n",
    "\"\"\"\n",
    "# Init pipeline with batchsize 1 on CPU for our example\n",
    "pipe = pipeline(task = 'zero-shot-classification', model='typeform/distilbert-base-uncased-mnli', batch_size=1, device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/devEnv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequires\n",
    "```\n",
    "pip install ray\n",
    "pip install torch\n",
    "pip install transformers\n",
    "pip install scikit-learn\n",
    "pip install psutil\n",
    "```\n",
    "https://towardsdatascience.com/parallel-inference-of-huggingface-transformers-on-cpus-4487c28abe23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict single text\n",
    "prediction = pipe(test_data[100], ['motorcycle', 'baseball'])\n",
    "print('Text:', prediction['sequence'])\n",
    "print('Labels:', prediction['labels'])\n",
    "print('Scores:', prediction['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Hey, the Lone Biker of the Apocalypse (see Raising Arizona) had flames coming\n",
      "out of both his exhaust pipes. I love to toggle the kill switch on my Sportster\n",
      "to produce flaming backfires, especially underneath overpasses at night (it's\n",
      "loud and lights up the whole underpass!!!\n",
      "Labels: ['motorcycle', 'baseball']\n",
      "Scores: [0.9970590472221375, 0.0029409313574433327]\n"
     ]
    }
   ],
   "source": [
    "# Predict single text\n",
    "prediction = pipe(test_data[100], ['motorcycle', 'baseball'])\n",
    "print('Text:', prediction['sequence'])\n",
    "print('Labels:', prediction['labels'])\n",
    "print('Scores:', prediction['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict multipe texts on single CPU and time the inference duration\n",
    "start = time.time()\n",
    "predictions = [pipe(text, ['motorcycle', 'baseball']) for text in test_data]\n",
    "end = time.time()\n",
    "print('Prediction time:', str(timedelta(seconds=end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devEnv",
   "language": "python",
   "name": "devenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
