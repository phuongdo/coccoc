{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d82aef84-265f-41f2-9fb8-32ca51d21a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cuda Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "828208f5-84a8-4418-9cbb-455745a4950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7637b50-8be1-4540-8bf3-a20096fc396d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CUDA devices\n",
      "id 0    b'NVIDIA GeForce RTX 2060 SUPER'                              [SUPPORTED]\n",
      "                      Compute Capability: 7.5\n",
      "                           PCI Device ID: 0\n",
      "                              PCI Bus ID: 1\n",
      "                                    UUID: GPU-8500da8a-ebb6-595d-cbda-381e217fd292\n",
      "                                Watchdog: Enabled\n",
      "             FP32/FP64 Performance Ratio: 32\n",
      "Summary:\n",
      "\t1/1 devices are supported\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.detect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "092a0f6c-891d-43a4-80a6-08681a36e19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launching a Cuda kernel from Numba is very easy. A kernel is defined by using the @cuda.jit decorator as\n",
    "@cuda.jit\n",
    "def an_empty_kernel():\n",
    "    \"\"\"A kernel that doesn't do anything.\"\"\"\n",
    "    # Get my current position in the global grid\n",
    "    [pos_x, pos_y] = cuda.grid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1b874a-b625-49e8-b42a-d66fb108dee7",
   "metadata": {},
   "source": [
    "The following commands define a two dimensional thread layout of  threads per block and 16x16  blocks. In total this gives us 256x256 threads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a499ab01-0bd9-45a8-af9f-dbfb0d539719",
   "metadata": {},
   "outputs": [],
   "source": [
    "threadsperblock = (16, 16) # Should be a multiple of 32 if possible.\n",
    "blockspergrid = (256, 256) # Blocks per grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5855004-e4fa-4668-bcbd-283a253c3a73",
   "metadata": {},
   "source": [
    "We can now launch all 16.8 million threads by calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c43eaa5-ecc8-4b65-862e-9b92ce99fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_empty_kernel[blockspergrid, threadsperblock]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a26ed5-6efb-4763-941b-c4e685ac8045",
   "metadata": {},
   "source": [
    "### Memory management\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73fd9ebc-3c3e-4ae4-ae6c-c5e8405e7f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.arange(10)\n",
    "device_arr = cuda.to_device(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "553c44c4-6ad4-4049-bda5-245614ae6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_arr = device_arr.copy_to_host() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fd87a68-ac66-403e-8b1d-4c8c1319ce54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host_array = np.empty(shape=device_arr.shape, dtype=device_arr.dtype)\n",
    "device_arr.copy_to_host(host_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9b9246b-4086-4577-8b5b-c06ef6d845c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "\n",
    "@vectorize(['int64(int64, int64)'], target='cuda')\n",
    "def add_ufunc(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a2f440b-0970-463a-b0ec-2db6d90a1829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a+b:\n",
      " [11 22 33 44]\n",
      "\n",
      "b_col + c:\n",
      " [[10 11 12 13]\n",
      " [24 25 26 27]\n",
      " [38 39 40 41]\n",
      " [52 53 54 55]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/bi/phuongdv/miniconda3/envs/gpu/lib/python3.9/site-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([10, 20, 30, 40])\n",
    "b_col = b[:, np.newaxis] # b as column array\n",
    "c = np.arange(4*4).reshape((4,4))\n",
    "\n",
    "print('a+b:\\n', add_ufunc(a, b))\n",
    "print()\n",
    "print('b_col + c:\\n', add_ufunc(b_col, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83de8f76-a229-4cb5-83b1-e1dc1c4412b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894 ns ± 11.5 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.add(b_col, c)   # NumPy on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "971d984b-b798-4ad6-9aaf-507ced6f15fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713 µs ± 2.02 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit add_ufunc(b_col, c) # Numba on GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f49aec4-7f14-444e-8dc0-8d1aad9a12b6",
   "metadata": {},
   "source": [
    "the GPU is a lot slower than the CPU. What happened??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "611d7ddb-78ff-461c-8b38-8f5c7f44a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math  # Note that for the CUDA target, we need to use the scalar functions from the math module, not NumPy\n",
    "\n",
    "SQRT_2PI = np.float32((2*math.pi)**0.5)  # Precompute this constant as a float32.  Numba will inline it at compile time.\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32)'], target='cuda')\n",
    "def gaussian_pdf(x, mean, sigma):\n",
    "    '''Compute the value of a Gaussian probability density function at x with given mean and sigma.'''\n",
    "    return math.exp(-0.5 * ((x - mean) / sigma)**2) / (sigma * SQRT_2PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b71e877-ead4-4bcd-88eb-1ddf5da6ebbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/bi/phuongdv/miniconda3/envs/gpu/lib/python3.9/site-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.01306025])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Gaussian distribution PDF a million times!\n",
    "x = np.random.uniform(-3, 3, size=1000000).astype(np.float32)\n",
    "mean = np.float32(0.0)\n",
    "sigma = np.float32(1.0)\n",
    "\n",
    "# Quick test\n",
    "gaussian_pdf(x[0], 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39be331e-536a-4973-9e20-0f8a2df59801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.8 ms ± 56.5 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats # for definition of gaussian distribution\n",
    "norm_pdf = scipy.stats.norm\n",
    "%timeit norm_pdf.pdf(x, loc=mean, scale=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7d8c1b1-fe47-4263-a584-713f9aa4eb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.79 ms ± 44.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit gaussian_pdf(x, mean, sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea309a8f-831b-4067-8266-b02c1dd23bce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
